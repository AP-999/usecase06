Please generate the following code:
1. Python Lambda function that prints the number and overall size of EBS disk volume and snapshots in eu-central-1.
ChatGPT
Of course! Below is a Python AWS Lambda function that retrieves and prints the number and overall size of both EBS disk volumes and snapshots in the Frankfurt (eu-central-1) region:

Python Lambda Function
python
Copy code
import boto3

def lambda_handler(event, context):
    # Initialize the EC2 client for the Frankfurt (eu-central-1) region
    ec2_client = boto3.client('ec2', region_name='eu-central-1')

    # Retrieve the details of all EBS volumes in the region
    volumes = ec2_client.describe_volumes()
    total_volumes_size_gb = sum(vol['Size'] for vol in volumes['Volumes'])
    total_volumes_count = len(volumes['Volumes'])

    # Retrieve the details of all EBS snapshots in the region
    snapshots = ec2_client.describe_snapshots(OwnerIds=['self'])
    total_snapshots_size_gb = sum(snap['VolumeSize'] for snap in snapshots['Snapshots'])
    total_snapshots_count = len(snapshots['Snapshots'])

    # Print the results
    print(f"Number of EBS Volumes in Frankfurt: {total_volumes_count}")
    print(f"Overall size of EBS Volumes in Frankfurt: {total_volumes_size_gb} GB")
    print(f"Number of EBS Snapshots in Frankfurt: {total_snapshots_count}")
    print(f"Overall size of EBS Snapshots in Frankfurt: {total_snapshots_size_gb} GB")

    return {
        'statusCode': 200,
        'body': 'Details retrieved and printed. Check Lambda logs.'
    }
Considerations:

Lambda Runtime: Make sure your Lambda function uses a Python runtime and includes the Boto3 library.
IAM Permissions: The IAM role attached to this Lambda function needs to have permissions to describe EC2 volumes and snapshots.
Deployment: After setting up and deploying this function in AWS Lambda, you can invoke it. You'll then need to check the CloudWatch logs for the Lambda function to see the printed details.



User
Please generate the following code:
1. Python Lambda function that prints the number and overall size of EBS disk volume and snapshots in eu-central-1 and writes this information in S3 bucket named s3-usecase06
ChatGPT
Absolutely! Below is a Python AWS Lambda function that retrieves the number and overall size of both EBS disk volumes and snapshots in the Frankfurt (eu-central-1) region. The information is printed to CloudWatch logs and also written to the s3-usecase06 bucket:

Python Lambda Function
python
Copy code
import boto3
import json

def lambda_handler(event, context):
    # Initialize the EC2 client for the Frankfurt (eu-central-1) region and S3 client
    ec2_client = boto3.client('ec2', region_name='eu-central-1')
    s3 = boto3.client('s3', region_name='eu-central-1')

    # Retrieve the details of all EBS volumes in the region
    volumes = ec2_client.describe_volumes()
    total_volumes_size_gb = sum(vol['Size'] for vol in volumes['Volumes'])
    total_volumes_count = len(volumes['Volumes'])

    # Retrieve the details of all EBS snapshots in the region
    snapshots = ec2_client.describe_snapshots(OwnerIds=['self'])
    total_snapshots_size_gb = sum(snap['VolumeSize'] for snap in snapshots['Snapshots'])
    total_snapshots_count = len(snapshots['Snapshots'])

    # Prepare the results for storage
    data = {
        'EBS_Volumes_Count': total_volumes_count,
        'EBS_Volumes_Total_Size_GB': total_volumes_size_gb,
        'EBS_Snapshots_Count': total_snapshots_count,
        'EBS_Snapshots_Total_Size_GB': total_snapshots_size_gb
    }

    # Print the results
    print(data)

    # Upload the data to S3 in a file named ebs_data.json
    s3.put_object(
        Bucket='s3-usecase06',
        Key='ebs_data.json',
        Body=json.dumps(data),
        ContentType='application/json'
    )

    return {
        'statusCode': 200,
        'body': 'EBS details retrieved and stored in s3-usecase06/ebs_data.json'
    }
Considerations:

Lambda Runtime: Ensure your Lambda runtime environment has the Boto3 library available.
IAM Permissions: The IAM role associated with this Lambda function should have permissions to:
Describe EC2 volumes and snapshots.
Write to the s3-usecase06 S3 bucket.
Deployment: After creating and configuring this Lambda function in AWS, you can invoke it to collect the EBS details and store them as specified.



User
Please generate the following code:
1. Python Lambda code with two functions. The function named ebs_info prints the number and overall size of EBS disk volume and snapshots in eu-central-1. The main function writes this information in the S3 bucket named s3-usecase06
ChatGPT
Certainly! Below is a Python AWS Lambda function with two functions: one named ebs_info that retrieves the number and overall size of both EBS disk volumes and snapshots in the Frankfurt (eu-central-1) region, and the main function (lambda_handler) that invokes ebs_info and writes its output to the s3-usecase06 bucket:

Python Lambda Function
python
Copy code
import boto3
import json

def ebs_info():
    # Initialize the EC2 client for the Frankfurt (eu-central-1) region
    ec2_client = boto3.client('ec2', region_name='eu-central-1')

    # Retrieve the details of all EBS volumes in the region
    volumes = ec2_client.describe_volumes()
    total_volumes_size_gb = sum(vol['Size'] for vol in volumes['Volumes'])
    total_volumes_count = len(volumes['Volumes'])

    # Retrieve the details of all EBS snapshots in the region
    snapshots = ec2_client.describe_snapshots(OwnerIds=['self'])
    total_snapshots_size_gb = sum(snap['VolumeSize'] for snap in snapshots['Snapshots'])
    total_snapshots_count = len(snapshots['Snapshots'])

    # Prepare the results
    data = {
        'EBS_Volumes_Count': total_volumes_count,
        'EBS_Volumes_Total_Size_GB': total_volumes_size_gb,
        'EBS_Snapshots_Count': total_snapshots_count,
        'EBS_Snapshots_Total_Size_GB': total_snapshots_size_gb
    }

    return data

def lambda_handler(event, context):
    # Fetch EBS info
    ebs_data = ebs_info()

    # Print the results
    print(ebs_data)

    # Initialize the S3 client
    s3 = boto3.client('s3', region_name='eu-central-1')

    # Upload the data to S3 in a file named ebs_data.json
    s3.put_object(
        Bucket='s3-usecase06',
        Key='ebs_data.json',
        Body=json.dumps(ebs_data),
        ContentType='application/json'
    )

    return {
        'statusCode': 200,
        'body': 'EBS details retrieved and stored in s3-usecase06/ebs_data.json'
    }
Considerations:

Lambda Runtime: Make sure your Lambda runtime environment has the Boto3 library available.
IAM Permissions: The IAM role associated with this Lambda function should have permissions to:
Describe EC2 volumes and snapshots.
Write to the s3-usecase06 S3 bucket.
Deployment: After creating and configuring this Lambda function in AWS, you can invoke it to collect the EBS details and store them as detailed above.

======
Please generate the following code:
1. Python Lambda function that prints the number and overall size of EBS disk volume and snapshots in eu-central-1 and writes this information in S3 bucket named s3-usecase06
ChatGPT
Absolutely! Below is a Python AWS Lambda function that retrieves the number and overall size of both EBS disk volumes and snapshots in the Frankfurt (eu-central-1) region. The information is printed to CloudWatch logs and also written to the s3-usecase06 bucket:

Python Lambda Function
python
Copy code
import boto3
import json

def lambda_handler(event, context):
    # Initialize the EC2 client for the Frankfurt (eu-central-1) region and S3 client
    ec2_client = boto3.client('ec2', region_name='eu-central-1')
    s3 = boto3.client('s3', region_name='eu-central-1')

    # Retrieve the details of all EBS volumes in the region
    volumes = ec2_client.describe_volumes()
    total_volumes_size_gb = sum(vol['Size'] for vol in volumes['Volumes'])
    total_volumes_count = len(volumes['Volumes'])

    # Retrieve the details of all EBS snapshots in the region
    snapshots = ec2_client.describe_snapshots(OwnerIds=['self'])
    total_snapshots_size_gb = sum(snap['VolumeSize'] for snap in snapshots['Snapshots'])
    total_snapshots_count = len(snapshots['Snapshots'])

    # Prepare the results for storage
    data = {
        'EBS_Volumes_Count': total_volumes_count,
        'EBS_Volumes_Total_Size_GB': total_volumes_size_gb,
        'EBS_Snapshots_Count': total_snapshots_count,
        'EBS_Snapshots_Total_Size_GB': total_snapshots_size_gb
    }

    # Print the results
    print(data)

    # Upload the data to S3 in a file named ebs_data.json
    s3.put_object(
        Bucket='s3-usecase06',
        Key='ebs_data.json',
        Body=json.dumps(data),
        ContentType='application/json'
    )

    return {
        'statusCode': 200,
        'body': 'EBS details retrieved and stored in s3-usecase06/ebs_data.json'
    }
Considerations:

Lambda Runtime: Ensure your Lambda runtime environment has the Boto3 library available.
IAM Permissions: The IAM role associated with this Lambda function should have permissions to:
Describe EC2 volumes and snapshots.
Write to the s3-usecase06 S3 bucket.
Deployment: After creating and configuring this Lambda function in AWS, you can invoke it to collect the EBS details and store them as specified.

========

Please generate the following code:
1. Python Lambda code with two functions. The function named ebs_info prints the number and overall size of EBS disk volume and snapshots in eu-central-1. The main function writes this information in the S3 bucket named s3-usecase06
ChatGPT
Certainly! Below is a Python AWS Lambda function with two functions: one named ebs_info that retrieves the number and overall size of both EBS disk volumes and snapshots in the Frankfurt (eu-central-1) region, and the main function (lambda_handler) that invokes ebs_info and writes its output to the s3-usecase06 bucket:

Python Lambda Function
python
Copy code
import boto3
import json

def ebs_info():
    # Initialize the EC2 client for the Frankfurt (eu-central-1) region
    ec2_client = boto3.client('ec2', region_name='eu-central-1')

    # Retrieve the details of all EBS volumes in the region
    volumes = ec2_client.describe_volumes()
    total_volumes_size_gb = sum(vol['Size'] for vol in volumes['Volumes'])
    total_volumes_count = len(volumes['Volumes'])

    # Retrieve the details of all EBS snapshots in the region
    snapshots = ec2_client.describe_snapshots(OwnerIds=['self'])
    total_snapshots_size_gb = sum(snap['VolumeSize'] for snap in snapshots['Snapshots'])
    total_snapshots_count = len(snapshots['Snapshots'])

    # Prepare the results
    data = {
        'EBS_Volumes_Count': total_volumes_count,
        'EBS_Volumes_Total_Size_GB': total_volumes_size_gb,
        'EBS_Snapshots_Count': total_snapshots_count,
        'EBS_Snapshots_Total_Size_GB': total_snapshots_size_gb
    }

    return data

def lambda_handler(event, context):
    # Fetch EBS info
    ebs_data = ebs_info()

    # Print the results
    print(ebs_data)

    # Initialize the S3 client
    s3 = boto3.client('s3', region_name='eu-central-1')

    # Upload the data to S3 in a file named ebs_data.json
    s3.put_object(
        Bucket='s3-usecase06',
        Key='ebs_data.json',
        Body=json.dumps(ebs_data),
        ContentType='application/json'
    )

    return {
        'statusCode': 200,
        'body': 'EBS details retrieved and stored in s3-usecase06/ebs_data.json'
    }
Considerations:

Lambda Runtime: Make sure your Lambda runtime environment has the Boto3 library available.
IAM Permissions: The IAM role associated with this Lambda function should have permissions to:
Describe EC2 volumes and snapshots.
Write to the s3-usecase06 S3 bucket.
Deployment: After creating and configuring this Lambda function in AWS, you can invoke it to collect the EBS details and store them as detailed above.



